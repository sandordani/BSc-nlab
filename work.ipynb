{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from loadData import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import syft as sy\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "Attributes:\n",
    "    -denseOutputData\n",
    "    -sparseOutputData\n",
    "    -denseInputData\n",
    "    -denseSampleIndex\n",
    "    -sparseInputData\n",
    "    -sparseSampleIndex\n",
    "    -allSamples\n",
    "    -folds\n",
    "\"\"\"\"\"\n",
    "data = DataLoader(datasetName='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "hook.local_worker.is_client_worker = False\n",
    "\n",
    "server = hook.local_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.denseOutputData = data.denseOutputData.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.23 GiB (GPU 0; 2.00 GiB total capacity; 0 bytes already allocated; 1.42 GiB free; 0 bytes reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e07d4692e169>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mout_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\syft\\generic\\frameworks\\hook\\trace.py\u001b[0m in \u001b[0;36mtrace_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0msyft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\syft\\generic\\frameworks\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# means that there is a wrapper to remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\syft\\generic\\frameworks\\hook\\hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m                     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.23 GiB (GPU 0; 2.00 GiB total capacity; 0 bytes already allocated; 1.42 GiB free; 0 bytes reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(data.denseInputData, dtype=torch.float32, requires_grad=True)\n",
    "# i = torch.LongTensor([data.sparseOutputData.row,\n",
    "#                           data.sparseOutputData.col])\n",
    "# v = torch.FloatTensor(data.sparseOutputData.data)\n",
    "# y = torch.sparse.FloatTensor(i, v, torch.Size(data.sparseOutputData.shape)).requires_grad_(True)\n",
    "y = torch.tensor(data.denseOutputData, dtype=torch.float32, requires_grad=True)\n",
    "in_dim  = x.size()[1]\n",
    "out_dim = y.size()[1]\n",
    "x.cuda()\n",
    "y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.sparseOutputData.shape)\n",
    "print(y.size())\n",
    "print(x.size())\n",
    "#plt.scatter(np.arange(data.sparseOutputData.data.size), data.sparseOutputData.data)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers = 10\n",
    "workers = []\n",
    "data_per_worker = int(x.size()[0] / nworkers)\n",
    "# data_per_worker = 1\n",
    "x_pointers = []\n",
    "y_pointers = []\n",
    "\n",
    "#itt definiálom a workereket\n",
    "print(\"Creating workers...\")\n",
    "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
    "for i in range(nworkers):\n",
    "    print(\"Worker id:\", 'w'+str(i), \"has data from:\",(i) * data_per_worker, \"to\", (i+1) * data_per_worker)\n",
    "      \n",
    "    #tenzorok másolása workereknek\n",
    "#     xi = x[i * data_per_worker: (i+1) * data_per_worker].clone().detach().requires_grad_(True).tag('input_data')\n",
    "#     yi = y[i * data_per_worker: (i+1) * data_per_worker].clone().detach().requires_grad_(True).tag('output_data')\n",
    "#     xi = torch.tensor(data.denseInputData[i * data_per_worker: (i+1) * data_per_worker], dtype=torch.float32, requires_grad=True).tag('input_data')\n",
    "#     yi = torch.tensor(data.denseOutputData[i * data_per_worker: (i+1) * data_per_worker], dtype=torch.float32, requires_grad=True).tag('output_data')\n",
    "    \n",
    "    xi = x[i * data_per_worker: (i+1) * data_per_worker].clone().tag('input_data')\n",
    "    yi = y[i * data_per_worker: (i+1) * data_per_worker].clone().tag('output_data')\n",
    "#     workers.append(sy.VirtualWorker(hook, id='w'+str(i), data=(xi, yi)))\n",
    "    workers.append(sy.VirtualWorker(hook, id='w'+str(i)))\n",
    "    \n",
    "    x_pointers.append(xi.send(workers[i]))\n",
    "    y_pointers.append(yi.send(workers[i]))\n",
    "    \n",
    "#     x_pointers.append(workers[i].search('input_data')[0])\n",
    "#     y_pointers.append(workers[i].search('output_data')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Innen kell újra csak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 1000\n",
    "class TrunkNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrunkNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_features=in_dim, out_features=latent_dim)\n",
    "        self.weight = self.layer1.weight\n",
    "        self.bias = self.layer1.bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.layer1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HeadNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_features=latent_dim, out_features=out_dim)\n",
    "        self.weight = self.layer1.weight\n",
    "        self.bias = self.layer1.bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.1\n",
    "\n",
    "#ezt még használom később\n",
    "trunkNet = TrunkNet()\n",
    "trunkNet.cuda()\n",
    "# trunkNet.build(torch.zeros(in_dim))\n",
    "#ezt már nem\n",
    "headNetInit = HeadNet()\n",
    "headNetInit.cuda()\n",
    "# headNetInit.build(torch.zeros(latent_dim))\n",
    "\n",
    "head_pointers = []\n",
    "optimizer_pointers = []\n",
    "\n",
    "print(\"Sending head networks\")\n",
    "for i in range(nworkers):\n",
    "    print(\"Sending model:\",i)\n",
    "    head_pointers.append(headNetInit.copy().send(workers[i]))\n",
    "print(\"Models sent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @sy.func2plan(args_shape=[(data_per_worker, out_dim),(data_per_worker, out_dim)])\n",
    "# def plan_MSE(preds, expected):\n",
    "#     return ((preds - expected) **2).sum() / data_per_worker\n",
    "# plan_MSE.is_built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "def train(epochs, worker_iters, batch_size):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        \n",
    "        print(\"Epoch\", epoch)\n",
    "        print(\" Sending models...\")\n",
    "        \n",
    "        trunk_pointers = []\n",
    "        optimizer_pointers = []\n",
    "        head_optimizer_pointers = []\n",
    "        for i in range(nworkers):\n",
    "            trunk_pointers.append(trunkNet.copy().send(workers[i]))\n",
    "            optimizer_pointers.append(optim.SGD([\n",
    "                {'params': trunk_pointers[i].parameters()},\n",
    "                {'params': head_pointers[i].parameters(), 'lr': 0.001}\n",
    "            ],lr=learningRate))\n",
    "\n",
    "\n",
    "        losses = []\n",
    "        for wi in range(worker_iters):\n",
    "            preds = []\n",
    "            losses = [None] * nworkers\n",
    "\n",
    "            print(\" Worker iterations\", wi)\n",
    "            for i in range(nworkers):\n",
    "                print(\"  Worker\", i, end =\" \")\n",
    "                for b in range(int(data_per_worker/batch_size)):\n",
    "                    optimizer_pointers[i].zero_grad()\n",
    "                    preds.append(head_pointers[i](trunk_pointers[i](x_pointers[i][b*batch_size:(b+1)*batch_size])))\n",
    "                    losses[i] = (((preds[i] - y_pointers[i][b*batch_size:(b+1)*batch_size]) **2).sum() /data_per_worker / int(data_per_worker/batch_size))\n",
    "                    losses[i].backward(retain_graph=True)\n",
    "                \n",
    "                    optimizer_pointers[i].step()\n",
    "                \n",
    "                losses[i] = losses[i].get().data\n",
    "                \n",
    "            print(\"\")\n",
    "        \n",
    "        print(\" Sending back models...\")\n",
    "        for i in range(nworkers):\n",
    "            trunk_pointers[i].move(secure_worker)\n",
    "                \n",
    "        print(\" Averaging weights\")\n",
    "        with torch.no_grad():\n",
    "            sumw = 0\n",
    "            sumb = 0\n",
    "            for i in range(nworkers):\n",
    "                sumw += trunk_pointers[i].weight.data\n",
    "                sumb += trunk_pointers[i].bias.data\n",
    "                \n",
    "            trunkNet.weight.set_((sumw / nworkers).get())\n",
    "            trunkNet.bias.set_((sumb / nworkers).get())\n",
    "\n",
    "        sumloss = 0\n",
    "        for i in range(nworkers):\n",
    "            sumloss += losses[i]\n",
    "            \n",
    "        loss_history.append((sumloss/nworkers).item)\n",
    "        print(\"Average loss:\", sumloss/nworkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(20,1,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
